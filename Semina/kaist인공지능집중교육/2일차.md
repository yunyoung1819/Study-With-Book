# KAIST 인공지능 집중교육 2일차 요약 
-----------------------------------------------------------------------------------

## 확률적 결정이 가능한 이진 분류 (Binary Classification)

- 누군가가 우리의 분류 결정에 확신이 어느정도 있냐고 묻는다면?

````
"당신은 0.8의 확률로 승진을 하게 될 것이다."

"이 사진은 70%의 확률로 강아지일 것이다."
````

- 이러한 유형의 이진분류를 logistic regression이라 한다. 


### Multiclass Logistic Regression을 위한 softmax 함수

- softmax 함수는 K개의 실수를 입력으로 받아 입력 값의 exponential에 비례하는 k개의 (고양이, 강아지, 또는
원숭이 등의 클래스들에 대응하는) 확률값을 출력하는 함수이다. 


### Decision Tree

- 일반적으로 data mining에서 사용되는 기법이다.
- 모든 decision과 해당 decision의 결과에 대응하는 결과들을 tree 구조로 도식화 
- 예: 건강 보험 회사가 가입 희망자가 보험 가입에 적합한지 아닌지를 일련의 질문을 통해 결정하려고 하는 경우,
제안 받은 일자리에 취직할지 아닐지를 결정하고자 하는 경우 


### Linear Regression

- 주어진 데이터들에 직선(또는 hyperplane)을 맞추고, 이를 통해 새로운 데이터 x가 주어졌을 때, 
이에 대응하는 y값을 예측한다. 


### Polynomial Regression

![poly](../image/poly.PNG)

- 이 경우 직선은 좋지 않은 선택이다.

### Regularization

- Overfitting은 종종 일부 변수들이 지나치게 큰 값을 가짐으로 인해 발생한다.
- 이러한 동작을 확인 및 조절하는 간단한 방법은 loss function에 penalty term을 추가하는 것이다.


### Bias versus Variance in Prediction (Regression) Error

- 좋은 예측 모델(또는 regression 함수)는 낮은 variance와 낮은 bias를 가져야 한다.


## Deep Learning

- 단순 신경망(Simple Neural Network)
- 심층 신경망 
    - 여러 개의 hidden layers 


### Why Deep Learning

- Deep learning에서는 단순 machine learning과는 달리 특징 추출(feature extraction)을 스스로(자동으로) 학습함
- The Perceptron
    - 심층 신경망의 기본 구성요소

    
 ### 보편적인 비선형 함수

 - Sigmoid Function
 - Hyperbolic Tangent
 - Rectified Linear Unit (ReLU)
 
 
 ### Gradient Descent (GD)
 
 - Batch GD(기본적인 형태의 GD
 
 1. Initialize weights randomly
 2. Loop until convergence
 3. Compute gradient
 4. Update weight
 5. Return weight
 
 
 ### Mini-Batch GD
 
 1. Initialize weight randomly
 2. Loop until convergence
 3. Pick batch of B data points
 4. Compute gradient
 4. Update weights
 5. Return weights
 
 ### Adam Optimizer
 
- 기존의 gradient descent 방식을 약간 수정하여 network의 weights을 업데이트하는 방식
 
 
 ### Backpropagation을 이용한 Gradients 계산 
 
- Layer I의 node i와 layer J의 node j를 연결하는 hidden layer weight Wij의 Gradient
- Forward Propagation
- Back Propagation


### Forward/Backpropagation/Update 예시

![딥러닝](../image/딥러닝.PNG)
